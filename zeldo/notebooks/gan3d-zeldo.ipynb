{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rF2x3qooyBTI"
   },
   "source": [
    "# 3D Deep Convolutional Generative Adversarial Network for Zeldovich Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZKbyU2-AiY-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wx-zNbLqB4K8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YzTlj4YdCip_"
   },
   "outputs": [],
   "source": [
    "# To generate GIFs\n",
    "!pip install -q imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "### Load and prepare the dataset\n",
    "\n",
    "You will use the ZA dataset to train the generator and the discriminator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4fYMGxGhrna"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "nGrid = 16\n",
    "\n",
    "class zeldo_data:\n",
    "    def load_data():\n",
    "\n",
    "        z = 50\n",
    "        hdf5_path = \"../data/z\" + str(z)+\"_100.hdf5\"\n",
    "        hdf5_file = h5py.File(hdf5_path, mode='r')\n",
    "        sim_z50 = hdf5_file[\"sims_z\" + str(z)]\n",
    "        \n",
    "        z = 0\n",
    "        hdf5_path = \"../data/z\" + str(z)+\"_100.hdf5\"\n",
    "        hdf5_file = h5py.File(hdf5_path, mode='r')\n",
    "        sim_z0 = hdf5_file[\"sims_z\" + str(z)]\n",
    "     \n",
    "        train_test_split = 0.9\n",
    "        split = np.int(train_test_split*sim_z0.shape[0])\n",
    "        \n",
    "        train_data = sim_z0[0:split, :, :, :]\n",
    "        train_target = sim_z50[0:split, :, :, :]\n",
    "        test_data = sim_z0[split:, :, :, :]\n",
    "        test_target = sim_z50[split:, :, :, :]\n",
    "        \n",
    "#         train_data = np.expand_dims(train_data, 0)\n",
    "#         test_data = np.expand_dims(test_data, 0)\n",
    "        \n",
    "        \n",
    "        return (train_data[:, :nGrid, :nGrid, :nGrid], train_target[:, :nGrid, :nGrid, :nGrid]), (test_data[:, :nGrid, :nGrid, :nGrid], test_target[:, :nGrid, :nGrid, :nGrid])\n",
    "    \n",
    "    \n",
    "(train_images, train_labels), (test_images, test_labels) = zeldo_data.load_data()\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFC2ghIdiZYE"
   },
   "outputs": [],
   "source": [
    "# train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "tmin = train_images.min()\n",
    "tmax = train_images.max()\n",
    "\n",
    "train_images = (train_images - tmin) / (tmax - tmin) # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4PIDhoDLbsZ"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 90\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yKCCQOoJ7cn"
   },
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tEyxE-GMC48"
   },
   "source": [
    "### The Generator\n",
    "\n",
    "The generator uses `tf.keras.layers.Conv2DTranspose` (upsampling) layers to produce an image from a seed (random noise). Start with a `Dense` layer that takes this seed as input, then upsample several times until you reach the desired image size of 28x28x1. Notice the `tf.keras.layers.LeakyReLU` activation for each layer, except the output layer which uses tanh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bpTcDqoLWjY"
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(4*4*4*2, use_bias=False, input_shape=(10,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((4, 4, 4, 2)))\n",
    "    assert model.output_shape == (None, 4, 4, 4, 2) # Note: None is the batch size\n",
    "\n",
    "#     model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.Conv3DTranspose(8, (4, 4, 4), strides=(1, 1, 1), padding='same', use_bias=False) )\n",
    "    assert model.output_shape == (None, 4, 4, 4, 8)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "#     model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(tf.keras.layers.Conv3DTranspose(16, (4, 4, 4), strides=(2, 2, 2), padding='same', use_bias=False) )\n",
    "    assert model.output_shape == (None, 8, 8, 8, 16)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "#     model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    model.add(tf.keras.layers.Conv3DTranspose(1, (2, 2, 2), strides=(2, 2, 2), padding='same', use_bias=False, activation='tanh') )\n",
    "    assert model.output_shape == (None, 16, 16, 16, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GyWgG09LCSJl"
   },
   "source": [
    "Use the (as yet untrained) generator to create an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gl7jcC7TdPTG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x148197d10>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 10])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(np.array(generated_image[0, :, :, 10, 0]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 16, 16, 16, 1])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0IKnaCtg6WE"
   },
   "source": [
    "### The Discriminator\n",
    "\n",
    "The discriminator is a CNN-based image classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dw2tPLmk2pEP"
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv3D(16, (4, 4, 4), strides=(2, 2, 2), padding='same', input_shape=(16, 16, 16, 1)) )\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv3D(64, (4, 4, 4), strides=(1, 1, 1), padding='same') )\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhPneagzCaQv"
   },
   "source": [
    "Use the (as yet untrained) discriminator to classify the generated images as real or fake. The model will be trained to output positive values for real images, and negative values for fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDkA05NE6QMs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00089369]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 16, 16, 16, 1])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Define the loss and optimizers\n",
    "\n",
    "Define loss functions and optimizers for both models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psQfmXxYKU3X"
   },
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKY_iPSPNWoj"
   },
   "source": [
    "### Discriminator loss\n",
    "\n",
    "This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jd-3GCUEiKtv"
   },
   "source": [
    "### Generator loss\n",
    "The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, we will compare the discriminators decisions on the generated images to an array of 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgIc7i0th_Iu"
   },
   "source": [
    "The discriminator and the generator optimizers are different since we will train two networks separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWtinsGDPJlV"
   },
   "source": [
    "### Save checkpoints\n",
    "This notebook also demonstrates how to save and restore models, which can be helpful in case a long running training task is interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA1w-7s2POEy"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Define the training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "noise_dim = 10\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jylSonrqSWfi"
   },
   "source": [
    "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3t5ibNo05jCB"
   },
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "    \n",
    "      print(images.shape, generated_images.shape)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "#       print(image_batch.shape)\n",
    "#       image_batch = image_batch[:, :, :, np.newaxis]\n",
    "      image_batch = np.expand_dims(image_batch, 4)\n",
    "#       print(image_batch.shape)\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aFF7Hk3XdeW"
   },
   "source": [
    "**Generate and save images**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 10, 0] * (tmax - tmin) + tmin, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZrd4CdjR-Fp"
   },
   "source": [
    "## Train the model\n",
    "Call the `train()` method defined above to train the generator and discriminator simultaneously. Note, training GANs can be tricky. It's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).\n",
    "\n",
    "At the beginning of the training, the generated images look like random noise. As training progresses, the generated digits will look increasingly real. After about 50 epochs, they resemble MNIST digits. This may take about one minute / epoch with the default settings on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ly3UN0SLLY2l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 64, 64, 64, 1) (8, 16, 16, 16, 1)\n",
      "WARNING:tensorflow:Model was constructed with shape Tensor(\"conv3d_13_input:0\", shape=(None, 16, 16, 16, 1), dtype=float32) for input (None, 16, 16, 16, 1), but it was re-called on a Tensor with incompatible shape (8, 64, 64, 64, 1).\n",
      "WARNING:tensorflow:Layer conv3d_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    <ipython-input-238-df8a83bd90a9>:12 train_step  *\n        real_output = discriminator(images, training=True)\n    /Users/nramachandra/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /Users/nramachandra/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py:267 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /Users/nramachandra/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py:717 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /Users/nramachandra/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py:891 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /Users/nramachandra/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:737 __call__\n        self.name)\n    /Users/nramachandra/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py:213 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_23 is incompatible with the layer: expected axis -1 of input shape to have value 32768 but received input with shape [8, 2097152]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-241-d152560ca122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-239-775943fa4aae>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mimage_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#       print(image_batch.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Produce images for the GIF as we go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    495\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    496\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 497\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    <ipython-input-238-df8a83bd90a9>:12 train_step  *\n        real_output = discriminator(images, training=True)\n    /Users/nramachandra/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /Users/nramachandra/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py:267 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /Users/nramachandra/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py:717 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /Users/nramachandra/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py:891 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /Users/nramachandra/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:737 __call__\n        self.name)\n    /Users/nramachandra/anaconda3/envs/env_tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py:213 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_23 is incompatible with the layer: expected axis -1 of input shape to have value 32768 but received input with shape [8, 2097152]\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfM4YcPVPkNO"
   },
   "source": [
    "Restore the latest checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhXsd0srPo8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x149dae7d0>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "## Create a GIF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WfO5wCdclHGL"
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5x3q9_Oe5q0A"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=576x576 at 0x149C69BD0>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NywiH3nL8guF"
   },
   "source": [
    "Use `imageio` to create an animated gif using the images saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGKQgENQ8lEI"
   },
   "outputs": [],
   "source": [
    "anim_file = 'zeldo_gan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  last = -1\n",
    "  for i,filename in enumerate(filenames):\n",
    "    frame = 2*(i**0.5)\n",
    "    if round(frame) > round(last):\n",
    "      last = frame\n",
    "    else:\n",
    "      continue\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "if IPython.version_info > (6,2,0,''):\n",
    "  display.Image(filename=anim_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:env_tf2]",
   "language": "python",
   "name": "conda-env-env_tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "sns.set_style(style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 8, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "nGrid = 8\n",
    "\n",
    "class zeldo_data:\n",
    "    def load_data():\n",
    "\n",
    "        z = 50\n",
    "        hdf5_path = \"../data/z\" + str(z)+\"_100.hdf5\"\n",
    "        hdf5_file = h5py.File(hdf5_path, mode='r')\n",
    "        sim_z50 = hdf5_file[\"sims_z\" + str(z)]\n",
    "        \n",
    "        z = 0\n",
    "        hdf5_path = \"../data/z\" + str(z)+\"_100.hdf5\"\n",
    "        hdf5_file = h5py.File(hdf5_path, mode='r')\n",
    "        sim_z0 = hdf5_file[\"sims_z\" + str(z)]\n",
    "     \n",
    "        train_test_split = 0.9\n",
    "        split = np.int(train_test_split*sim_z0.shape[0])\n",
    "        \n",
    "        train_data = sim_z0[0:split, :, :, :]\n",
    "        train_target = sim_z50[0:split, :, :, :]\n",
    "        test_data = sim_z0[split:, :, :, :]\n",
    "        test_target = sim_z50[split:, :, :, :]\n",
    "        \n",
    "        return (train_data[:, :nGrid, :nGrid, :nGrid], train_target[:, :nGrid, :nGrid, :nGrid]), (test_data[:, :nGrid, :nGrid, :nGrid], test_target[:, :nGrid, :nGrid, :nGrid])\n",
    "    \n",
    "    \n",
    "(train_images, train_labels), (test_images, test_labels) = zeldo_data.load_data()\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "tf.flags.DEFINE_float('learning_rate', .0005, 'Initial learning rate.')\n",
    "tf.flags.DEFINE_integer('epochs', 20, 'Number of steps to run trainer.')\n",
    "tf.flags.DEFINE_integer('batch_size', 1, 'Minibatch size')\n",
    "tf.flags.DEFINE_integer('latent_dim', 4, 'Number of latent dimensions')\n",
    "tf.flags.DEFINE_integer('test_image_number', 4, 'Number of test images to recover during training')\n",
    "tf.flags.DEFINE_integer('inputs_decoder', 8, 'Size of decoder input layer')\n",
    "tf.flags.DEFINE_string('dataset', 'zeldo', 'Dataset name [mnist, zeldo, fashion-mnist]')\n",
    "tf.flags.DEFINE_string('logdir', './logs', 'Logs folder')\n",
    "tf.flags.DEFINE_bool('plot_latent', True, 'Plot latent space')\n",
    "\n",
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and create results folders\n",
    "results_folder = os.path.join('Results', FLAGS.dataset)\n",
    "[os.makedirs(os.path.join(results_folder, folder)) for folder in ['Test', 'Train']\n",
    "    if not os.path.exists(os.path.join(results_folder, folder))]\n",
    "\n",
    "# Empty log folder\n",
    "try:\n",
    "    if not len(os.listdir(FLAGS.logdir)) == 0:\n",
    "        shutil.rmtree(FLAGS.logdir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "# data = zeldo_data if FLAGS.dataset == 'zeldo'\n",
    "(train_images, train_labels), (test_images, test_labels) = zeldo_data.load_data()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create tf dataset\n",
    "with tf.variable_scope(\"DataPipe\"):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "    dataset = dataset.map(lambda x: tf.image.convert_image_dtype([x], dtype=tf.float32))\n",
    "    dataset = dataset.batch(batch_size=FLAGS.batch_size).prefetch(FLAGS.batch_size)\n",
    "\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    input_batch = iterator.get_next()\n",
    "    input_batch = tf.reshape(input_batch, shape=[-1, nGrid, nGrid, nGrid, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(X):\n",
    "    activation = tf.nn.relu\n",
    "    with tf.variable_scope(\"Encoder\"):\n",
    "        x = tf.layers.conv3d(inputs=X, filters=16, kernel_size=[4,4,4], padding='same', activation=activation)\n",
    "        x = tf.layers.conv3d(inputs=x, filters=16, kernel_size=[4,4,4], padding='same', activation=activation)\n",
    "#         x = tf.layers.conv3d(inputs=x, filters=64, kernel_size=[4,4,4], padding='same', activation=activation)\n",
    "        x = tf.layers.flatten(x)\n",
    "\n",
    "        x = tf.layers.dense(x, units=8*FLAGS.latent_dim)\n",
    "        x = tf.layers.dense(x, units=4*FLAGS.latent_dim)\n",
    "        x = tf.layers.dense(x, units=2*FLAGS.latent_dim)\n",
    "\n",
    "        # Local latent variables\n",
    "        mean_ = tf.layers.dense(x, units=FLAGS.latent_dim, name='mean')\n",
    "        std_dev = tf.nn.softplus(tf.layers.dense(x, units=FLAGS.latent_dim), name='std_dev')  # softplus to force >0\n",
    "\n",
    "        # Reparametrization trick\n",
    "        epsilon = tf.random_normal(tf.stack([tf.shape(x)[0], FLAGS.latent_dim]), name='epsilon')\n",
    "        z = mean_ + tf.multiply(epsilon, std_dev)\n",
    "\n",
    "        return z, mean_, std_dev\n",
    "\n",
    "def decoder(z):\n",
    "    activation = tf.nn.relu\n",
    "    with tf.variable_scope(\"Decoder\"):\n",
    "        \n",
    "        x = tf.layers.dense(z, units=FLAGS.inputs_decoder, activation=activation)\n",
    "        x = tf.layers.dense(x, units=2*FLAGS.inputs_decoder, activation=activation)\n",
    "        x = tf.layers.dense(x, units=4*FLAGS.inputs_decoder, activation=activation)\n",
    "        x = tf.layers.dense(x, units=8*FLAGS.inputs_decoder, activation=activation)\n",
    "        \n",
    "        recovered_size = int(np.cbrt(FLAGS.inputs_decoder))\n",
    "        x = tf.reshape(x, [-1, recovered_size, recovered_size, recovered_size, 1])\n",
    "\n",
    "        x = tf.layers.conv3d_transpose(x, filters=16, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "        x = tf.layers.conv3d_transpose(x, filters=16, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "#         x = tf.layers.conv3d_transpose(x, filters=64, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "\n",
    "        x = tf.contrib.layers.flatten(x)\n",
    "\n",
    "        x = tf.layers.dense(x, units= nGrid*nGrid*nGrid, activation=None)\n",
    "\n",
    "        x = tf.layers.dense(x, units=nGrid*nGrid*nGrid, activation=tf.nn.sigmoid)\n",
    "        img = tf.reshape(x, shape=[-1, nGrid, nGrid, nGrid, 1])\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-8233669bd54d>:4: conv3d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv3d instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-8233669bd54d>:7: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-8233669bd54d>:9: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-8233669bd54d>:35: conv3d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv3d_transpose instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Link encoder and decoder\n",
    "z, mean_, std_dev = encoder(input_batch)\n",
    "output = decoder(z)\n",
    "\n",
    "# Reshape input and output to flat vectors\n",
    "flat_output = tf.reshape(output, [-1, nGrid*nGrid*nGrid])\n",
    "flat_input = tf.reshape(input_batch, [-1, nGrid*nGrid*nGrid])\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    img_loss = tf.reduce_sum(flat_input * -tf.log(flat_output) + (1 - flat_input) * -tf.log(1 - flat_output), 1)\n",
    "    latent_loss = 0.5 * tf.reduce_sum(tf.square(mean_) + tf.square(std_dev) - tf.log(tf.square(std_dev)) - 1, 1)\n",
    "    loss = tf.reduce_mean(img_loss + latent_loss)\n",
    "    tf.summary.scalar('batch_loss', loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "init_vars = [tf.local_variables_initializer(), tf.global_variables_initializer()]\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual epoch: 0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-11a7d04e948a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_image_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                             \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnGrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnGrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnGrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                             \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "# with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "with tf.Session(config=tf.ConfigProto()) as sess:\n",
    "\n",
    "    writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "\n",
    "    sess.run(init_vars)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "    for epoch in range(FLAGS.epochs):\n",
    "        sess.run(iterator.initializer)\n",
    "        print('Actual epoch: {}'.format(epoch))\n",
    "        print(epoch)\n",
    "        \n",
    "        \n",
    "\n",
    "        flag = True  # Show only first batch of epoch\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                sess.run(optimizer)\n",
    "                if flag:\n",
    "                    # Get input and recover output images comparison\n",
    "                    summ, target, output_ = sess.run([merged_summary_op, input_batch, output])\n",
    "                    f, axarr = plt.subplots(FLAGS.test_image_number, 2)\n",
    "\n",
    "                    for j in range(FLAGS.test_image_number):\n",
    "                        for pos, im in enumerate([target, output_]):\n",
    "                            axarr[j, pos].imshow(im[j].reshape((nGrid, nGrid, nGrid))[0], cmap='gray')\n",
    "                            axarr[j, pos].axis('off')\n",
    "                            print(j)\n",
    "\n",
    "                    plt.savefig(os.path.join(results_folder, 'Train/Epoch_{}').format(epoch))\n",
    "                    plt.close(f)\n",
    "                    flag = False\n",
    "                    writer.add_summary(summ, epoch)\n",
    "\n",
    "                    # Create artificial image from unit norm sample\n",
    "                    artificial_image = sess.run(output, feed_dict={z: np.random.normal(0, 1, (1, FLAGS.latent_dim))})\n",
    "                    plt.figure()\n",
    "                    with sns.axes_style(\"white\"):\n",
    "                        plt.imshow(artificial_image[0].reshape((nGrid, nGrid, nGrid))[0], cmap='gray')\n",
    "                    plt.savefig(os.path.join(results_folder, 'Test/{}'.format(epoch)))\n",
    "                    plt.close()\n",
    "\n",
    "                    # Create plot of latent space (only if latent dimensions are 2)\n",
    "                    if FLAGS.latent_dim == 2 and FLAGS.plot_latent:\n",
    "                        coords = sess.run(z, feed_dict={input_batch: test_images[..., np.newaxis]/255.})\n",
    "                        colormap = ListedColormap(sns.color_palette(sns.hls_palette(10, l=.45 , s=.8)).as_hex())\n",
    "                        plt.scatter(coords[:, 0], coords[:, 1], c=test_labels, cmap=colormap)\n",
    "\n",
    "                        cbar = plt.colorbar()\n",
    "\n",
    "                        plt.axis('off')\n",
    "                        plt.title('Latent space')\n",
    "                        plt.savefig(os.path.join(results_folder, 'Test/Latent_{}'.format(epoch)))\n",
    "                        plt.close()\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "        # Create mesh grid of values\n",
    "        values = np.arange(-3, 4, .5)\n",
    "        xx, yy = np.meshgrid(values, values)\n",
    "        input_holder = np.zeros((1, 2))\n",
    "        # Matrix that will contain the grid of images\n",
    "        container = np.zeros((nGrid * len(values), nGrid * len(values)))\n",
    "\n",
    "        for row in range(xx.shape[0]):\n",
    "            for col in range(xx.shape[1]):\n",
    "                input_holder[0, :] = [xx[row, col], yy[row, col]]\n",
    "                artificial_image = sess.run(output, feed_dict={z: input_holder})\n",
    "                container[row * nGrid: (row + 1) * nGrid, col * nGrid: (col + 1) * nGrid] = np.squeeze(artificial_image)\n",
    "\n",
    "        plt.imshow(container, cmap='gray')\n",
    "        plt.savefig(os.path.join(results_folder, 'Test/Space_{}'.format(epoch)))\n",
    "        plt.close(  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "simID = 0\n",
    "gen_z50 = im[:,:,:,:,0]\n",
    "slice = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (10,  8))\n",
    "ax[0].imshow(gen_z50[simID, slice, :, :], cmap='gray_r')\n",
    "ax[1].imshow(gen_z50[simID, :, slice, :], cmap='gray_r')\n",
    "ax[2].imshow(gen_z50[simID, :, :, slice], cmap='gray_r')\n",
    "\n",
    "# ax[1, 0].imshow(gen_z0[simID, slice, :, :], cmap='gray_r')\n",
    "# ax[1, 1].imshow(gen_z0[simID, :, slice, :], cmap='gray_r')\n",
    "# ax[1, 2].imshow(gen_z0[simID, :, :, slice], cmap='gray_r')\n",
    "\n",
    "ax[0].set_xlabel('X',fontsize=20)\n",
    "ax[1].set_xlabel('Y', fontsize=20)\n",
    "ax[2].set_xlabel('Z', fontsize=20)\n",
    "\n",
    "# ax[0, 0].set_ylabel('z = 50', rotation=0, fontsize=20, labelpad=40)\n",
    "# ax[1, 0].set_ylabel('z = 0', rotation=0, fontsize=20, labelpad=40)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "cvae.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

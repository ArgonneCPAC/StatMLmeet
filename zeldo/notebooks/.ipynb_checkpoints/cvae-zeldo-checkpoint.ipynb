{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "sns.set_style(style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 8, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "nGrid = 8\n",
    "\n",
    "class zeldo_data:\n",
    "    def load_data():\n",
    "\n",
    "        z = 50\n",
    "        hdf5_path = \"../data/z\" + str(z)+\"_100.hdf5\"\n",
    "        hdf5_file = h5py.File(hdf5_path, mode='r')\n",
    "        sim_z50 = hdf5_file[\"sims_z\" + str(z)]\n",
    "        \n",
    "        z = 0\n",
    "        hdf5_path = \"../data/z\" + str(z)+\"_100.hdf5\"\n",
    "        hdf5_file = h5py.File(hdf5_path, mode='r')\n",
    "        sim_z0 = hdf5_file[\"sims_z\" + str(z)]\n",
    "     \n",
    "        train_test_split = 0.9\n",
    "        split = np.int(train_test_split*sim_z0.shape[0])\n",
    "        \n",
    "        train_data = sim_z0[0:split, :, :, :]\n",
    "        train_target = sim_z50[0:split, :, :, :]\n",
    "        test_data = sim_z0[split:, :, :, :]\n",
    "        test_target = sim_z50[split:, :, :, :]\n",
    "        \n",
    "        return (train_data[:, :nGrid, :nGrid, :nGrid], train_target[:, :nGrid, :nGrid, :nGrid]), (test_data[:, :nGrid, :nGrid, :nGrid], test_target[:, :nGrid, :nGrid, :nGrid])\n",
    "    \n",
    "    \n",
    "(train_images, train_labels), (test_images, test_labels) = zeldo_data.load_data()\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "tf.flags.DEFINE_float('learning_rate', .0005, 'Initial learning rate.')\n",
    "tf.flags.DEFINE_integer('epochs', 20, 'Number of steps to run trainer.')\n",
    "tf.flags.DEFINE_integer('batch_size', 1, 'Minibatch size')\n",
    "tf.flags.DEFINE_integer('latent_dim', 4, 'Number of latent dimensions')\n",
    "tf.flags.DEFINE_integer('test_image_number', 4, 'Number of test images to recover during training')\n",
    "tf.flags.DEFINE_integer('inputs_decoder', 8, 'Size of decoder input layer')\n",
    "tf.flags.DEFINE_string('dataset', 'zeldo', 'Dataset name [mnist, zeldo, fashion-mnist]')\n",
    "tf.flags.DEFINE_string('logdir', './logs', 'Logs folder')\n",
    "tf.flags.DEFINE_bool('plot_latent', True, 'Plot latent space')\n",
    "\n",
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and create results folders\n",
    "results_folder = os.path.join('Results', FLAGS.dataset)\n",
    "[os.makedirs(os.path.join(results_folder, folder)) for folder in ['Test', 'Train']\n",
    "    if not os.path.exists(os.path.join(results_folder, folder))]\n",
    "\n",
    "# Empty log folder\n",
    "try:\n",
    "    if not len(os.listdir(FLAGS.logdir)) == 0:\n",
    "        shutil.rmtree(FLAGS.logdir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-511f91136c48>:13: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "# data = zeldo_data if FLAGS.dataset == 'zeldo'\n",
    "(train_images, train_labels), (test_images, test_labels) = zeldo_data.load_data()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create tf dataset\n",
    "with tf.variable_scope(\"DataPipe\"):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "    dataset = dataset.map(lambda x: tf.image.convert_image_dtype([x], dtype=tf.float32))\n",
    "    dataset = dataset.batch(batch_size=FLAGS.batch_size).prefetch(FLAGS.batch_size)\n",
    "\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    input_batch = iterator.get_next()\n",
    "    input_batch = tf.reshape(input_batch, shape=[-1, nGrid, nGrid, nGrid, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(X):\n",
    "    activation = tf.nn.relu\n",
    "    with tf.variable_scope(\"Encoder\"):\n",
    "        x = tf.layers.conv3d(inputs=X, filters=16, kernel_size=[4,4,4], padding='same', activation=activation)\n",
    "        x = tf.layers.conv3d(inputs=x, filters=16, kernel_size=[4,4,4], padding='same', activation=activation)\n",
    "#         x = tf.layers.conv3d(inputs=x, filters=64, kernel_size=[4,4,4], padding='same', activation=activation)\n",
    "        x = tf.layers.flatten(x)\n",
    "\n",
    "        x = tf.layers.dense(x, units=8*FLAGS.latent_dim)\n",
    "        x = tf.layers.dense(x, units=4*FLAGS.latent_dim)\n",
    "        x = tf.layers.dense(x, units=2*FLAGS.latent_dim)\n",
    "\n",
    "        # Local latent variables\n",
    "        mean_ = tf.layers.dense(x, units=FLAGS.latent_dim, name='mean')\n",
    "        std_dev = tf.nn.softplus(tf.layers.dense(x, units=FLAGS.latent_dim), name='std_dev')  # softplus to force >0\n",
    "\n",
    "        # Reparametrization trick\n",
    "        epsilon = tf.random_normal(tf.stack([tf.shape(x)[0], FLAGS.latent_dim]), name='epsilon')\n",
    "        z = mean_ + tf.multiply(epsilon, std_dev)\n",
    "\n",
    "        return z, mean_, std_dev\n",
    "\n",
    "def decoder(z):\n",
    "    activation = tf.nn.relu\n",
    "    with tf.variable_scope(\"Decoder\"):\n",
    "        \n",
    "        x = tf.layers.dense(z, units=FLAGS.inputs_decoder, activation=activation)\n",
    "        x = tf.layers.dense(x, units=2*FLAGS.inputs_decoder, activation=activation)\n",
    "        x = tf.layers.dense(x, units=4*FLAGS.inputs_decoder, activation=activation)\n",
    "        x = tf.layers.dense(x, units=8*FLAGS.inputs_decoder, activation=activation)\n",
    "        \n",
    "        recovered_size = int(np.cbrt(FLAGS.inputs_decoder))\n",
    "        x = tf.reshape(x, [-1, recovered_size, recovered_size, recovered_size, 1])\n",
    "\n",
    "        x = tf.layers.conv3d_transpose(x, filters=16, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "        x = tf.layers.conv3d_transpose(x, filters=16, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "#         x = tf.layers.conv3d_transpose(x, filters=64, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "\n",
    "        x = tf.contrib.layers.flatten(x)\n",
    "\n",
    "        x = tf.layers.dense(x, units= nGrid*nGrid*nGrid, activation=None)\n",
    "\n",
    "        x = tf.layers.dense(x, units=nGrid*nGrid*nGrid, activation=tf.nn.sigmoid)\n",
    "        img = tf.reshape(x, shape=[-1, nGrid, nGrid, nGrid, 1])\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link encoder and decoder\n",
    "z, mean_, std_dev = encoder(input_batch)\n",
    "output = decoder(z)\n",
    "\n",
    "# Reshape input and output to flat vectors\n",
    "flat_output = tf.reshape(output, [-1, nGrid*nGrid*nGrid])\n",
    "flat_input = tf.reshape(input_batch, [-1, nGrid*nGrid*nGrid])\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    img_loss = tf.reduce_sum(flat_input * -tf.log(flat_output) + (1 - flat_input) * -tf.log(1 - flat_output), 1)\n",
    "    latent_loss = 0.5 * tf.reduce_sum(tf.square(mean_) + tf.square(std_dev) - tf.log(tf.square(std_dev)) - 1, 1)\n",
    "    loss = tf.reduce_mean(img_loss + latent_loss)\n",
    "    tf.summary.scalar('batch_loss', loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "init_vars = [tf.local_variables_initializer(), tf.global_variables_initializer()]\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "# with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "with tf.Session(config=tf.ConfigProto()) as sess:\n",
    "\n",
    "    writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "\n",
    "    sess.run(init_vars)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "    for epoch in range(FLAGS.epochs):\n",
    "        sess.run(iterator.initializer)\n",
    "        print('Actual epoch: {}'.format(epoch))\n",
    "        print(epoch)\n",
    "        \n",
    "        \n",
    "\n",
    "        flag = True  # Show only first batch of epoch\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                sess.run(optimizer)\n",
    "                if flag:\n",
    "                    # Get input and recover output images comparison\n",
    "                    summ, target, output_ = sess.run([merged_summary_op, input_batch, output])\n",
    "                    f, axarr = plt.subplots(FLAGS.test_image_number, 2)\n",
    "\n",
    "                    only1 = True\n",
    "                    \n",
    "                    if only1: \n",
    "                        plt.imshow(im[0].reshape((nGrid, nGrid, nGrid))[0], cmap='gray')\n",
    "                    else: \n",
    "                        for j in range(FLAGS.test_image_number):\n",
    "                            for pos, im in enumerate([target, output_]):\n",
    "                                axarr[j, pos].imshow(im[j].reshape((nGrid, nGrid, nGrid))[0], cmap='gray')\n",
    "                                axarr[j, pos].axis('off')\n",
    "                                print(j)\n",
    "\n",
    "                    plt.savefig(os.path.join(results_folder, 'Train/Epoch_{}').format(epoch))\n",
    "                    plt.close(f)\n",
    "                    flag = False\n",
    "                    writer.add_summary(summ, epoch)\n",
    "\n",
    "                    # Create artificial image from unit norm sample\n",
    "                    artificial_image = sess.run(output, feed_dict={z: np.random.normal(0, 1, (1, FLAGS.latent_dim))})\n",
    "                    plt.figure()\n",
    "                    with sns.axes_style(\"white\"):\n",
    "                        plt.imshow(artificial_image[0].reshape((nGrid, nGrid, nGrid))[0], cmap='gray')\n",
    "                    plt.savefig(os.path.join(results_folder, 'Test/{}'.format(epoch)))\n",
    "                    plt.close()\n",
    "\n",
    "                    # Create plot of latent space (only if latent dimensions are 2)\n",
    "                    if FLAGS.latent_dim == 2 and FLAGS.plot_latent:\n",
    "                        coords = sess.run(z, feed_dict={input_batch: test_images[..., np.newaxis]})\n",
    "                        colormap = ListedColormap(sns.color_palette(sns.hls_palette(10, l=.45 , s=.8)).as_hex())\n",
    "                        plt.scatter(coords[:, 0], coords[:, 1], c=test_labels, cmap=colormap)\n",
    "\n",
    "                        cbar = plt.colorbar()\n",
    "\n",
    "                        plt.axis('off')\n",
    "                        plt.title('Latent space')\n",
    "                        plt.savefig(os.path.join(results_folder, 'Test/Latent_{}'.format(epoch)))\n",
    "                        plt.close()\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "        # Create mesh grid of values\n",
    "        values = np.arange(-3, 4, .5)\n",
    "        xx, yy = np.meshgrid(values, values)\n",
    "        input_holder = np.zeros((1, 2))\n",
    "        # Matrix that will contain the grid of images\n",
    "        container = np.zeros((nGrid * len(values), nGrid * len(values)))\n",
    "\n",
    "        for row in range(xx.shape[0]):\n",
    "            for col in range(xx.shape[1]):\n",
    "                input_holder[0, :] = [xx[row, col], yy[row, col]]\n",
    "                artificial_image = sess.run(output, feed_dict={z: input_holder})\n",
    "                container[row * nGrid: (row + 1) * nGrid, col * nGrid: (col + 1) * nGrid] = np.squeeze(artificial_image)\n",
    "\n",
    "        plt.imshow(container, cmap='gray')\n",
    "        plt.savefig(os.path.join(results_folder, 'Test/Space_{}'.format(epoch)))\n",
    "        plt.close(  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "simID = 0\n",
    "gen_z50 = im[:,:,:,:,0]\n",
    "slice = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize = (10,  8))\n",
    "ax[0].imshow(gen_z50[simID, slice, :, :], cmap='gray_r')\n",
    "ax[1].imshow(gen_z50[simID, :, slice, :], cmap='gray_r')\n",
    "ax[2].imshow(gen_z50[simID, :, :, slice], cmap='gray_r')\n",
    "\n",
    "# ax[1, 0].imshow(gen_z0[simID, slice, :, :], cmap='gray_r')\n",
    "# ax[1, 1].imshow(gen_z0[simID, :, slice, :], cmap='gray_r')\n",
    "# ax[1, 2].imshow(gen_z0[simID, :, :, slice], cmap='gray_r')\n",
    "\n",
    "ax[0].set_xlabel('X',fontsize=20)\n",
    "ax[1].set_xlabel('Y', fontsize=20)\n",
    "ax[2].set_xlabel('Z', fontsize=20)\n",
    "\n",
    "# ax[0, 0].set_ylabel('z = 50', rotation=0, fontsize=20, labelpad=40)\n",
    "# ax[1, 0].set_ylabel('z = 0', rotation=0, fontsize=20, labelpad=40)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "cvae.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

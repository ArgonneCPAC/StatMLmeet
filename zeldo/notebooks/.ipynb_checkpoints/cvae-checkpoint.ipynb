{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "sns.set_style(style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "tf.flags.DEFINE_float('learning_rate', .0005, 'Initial learning rate.')\n",
    "tf.flags.DEFINE_integer('epochs', 1, 'Number of steps to run trainer.')\n",
    "tf.flags.DEFINE_integer('batch_size', 8, 'Minibatch size')\n",
    "tf.flags.DEFINE_integer('latent_dim', 2, 'Number of latent dimensions')\n",
    "tf.flags.DEFINE_integer('test_image_number', 5, 'Number of test images to recover during training')\n",
    "tf.flags.DEFINE_integer('inputs_decoder', 49, 'Size of decoder input layer')\n",
    "tf.flags.DEFINE_string('dataset', 'mnist', 'Dataset name [mnist, fashion-mnist]')\n",
    "tf.flags.DEFINE_string('logdir', './logs', 'Logs folder')\n",
    "tf.flags.DEFINE_bool('plot_latent', True, 'Plot latent space')\n",
    "\n",
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and create results folders\n",
    "results_folder = os.path.join('Results', FLAGS.dataset)\n",
    "[os.makedirs(os.path.join(results_folder, folder)) for folder in ['Test', 'Train']\n",
    "    if not os.path.exists(os.path.join(results_folder, folder))]\n",
    "\n",
    "# Empty log folder\n",
    "try:\n",
    "    if not len(os.listdir(FLAGS.logdir)) == 0:\n",
    "        shutil.rmtree(FLAGS.logdir)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "data = keras.datasets.mnist if FLAGS.dataset == 'mnist' else keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = data.load_data()\n",
    "\n",
    "# Create tf dataset\n",
    "with tf.variable_scope(\"DataPipe\"):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "    dataset = dataset.map(lambda x: tf.image.convert_image_dtype([x], dtype=tf.float32))\n",
    "    dataset = dataset.batch(batch_size=FLAGS.batch_size).prefetch(FLAGS.batch_size)\n",
    "\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    input_batch = iterator.get_next()\n",
    "    input_batch = tf.reshape(input_batch, shape=[-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(X):\n",
    "    activation = tf.nn.relu\n",
    "    with tf.variable_scope(\"Encoder\"):\n",
    "        x = tf.layers.conv2d(X, filters=64, kernel_size=4, strides=2, padding='same', activation=activation)\n",
    "        x = tf.layers.conv2d(x, filters=64, kernel_size=4, strides=2, padding='same', activation=activation)\n",
    "        x = tf.layers.conv2d(x, filters=64, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "        x = tf.layers.flatten(x)\n",
    "\n",
    "        # Local latent variables\n",
    "        mean_ = tf.layers.dense(x, units=FLAGS.latent_dim, name='mean')\n",
    "        std_dev = tf.nn.softplus(tf.layers.dense(x, units=FLAGS.latent_dim), name='std_dev')  # softplus to force >0\n",
    "\n",
    "        # Reparametrization trick\n",
    "        epsilon = tf.random_normal(tf.stack([tf.shape(x)[0], FLAGS.latent_dim]), name='epsilon')\n",
    "        z = mean_ + tf.multiply(epsilon, std_dev)\n",
    "\n",
    "        return z, mean_, std_dev\n",
    "\n",
    "\n",
    "def decoder(z):\n",
    "    activation = tf.nn.relu\n",
    "    with tf.variable_scope(\"Decoder\"):\n",
    "        x = tf.layers.dense(z, units=FLAGS.inputs_decoder, activation=activation)\n",
    "        x = tf.layers.dense(x, units=FLAGS.inputs_decoder, activation=activation)\n",
    "        recovered_size = int(np.sqrt(FLAGS.inputs_decoder))\n",
    "        x = tf.reshape(x, [-1, recovered_size, recovered_size, 1])\n",
    "\n",
    "        x = tf.layers.conv2d_transpose(x, filters=64, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "        x = tf.layers.conv2d_transpose(x, filters=64, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "        x = tf.layers.conv2d_transpose(x, filters=64, kernel_size=4, strides=1, padding='same', activation=activation)\n",
    "\n",
    "        x = tf.contrib.layers.flatten(x)\n",
    "        x = tf.layers.dense(x, units=28 * 28, activation=None)\n",
    "\n",
    "        x = tf.layers.dense(x, units=28 * 28, activation=tf.nn.sigmoid)\n",
    "        img = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link encoder and decoder\n",
    "z, mean_, std_dev = encoder(input_batch)\n",
    "output = decoder(z)\n",
    "\n",
    "# Reshape input and output to flat vectors\n",
    "flat_output = tf.reshape(output, [-1, 28 * 28])\n",
    "flat_input = tf.reshape(input_batch, [-1, 28 * 28])\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    img_loss = tf.reduce_sum(flat_input * -tf.log(flat_output) + (1 - flat_input) * -tf.log(1 - flat_output), 1)\n",
    "    latent_loss = 0.5 * tf.reduce_sum(tf.square(mean_) + tf.square(std_dev) - tf.log(tf.square(std_dev)) - 1, 1)\n",
    "    loss = tf.reduce_mean(img_loss + latent_loss)\n",
    "    tf.summary.scalar('batch_loss', loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "init_vars = [tf.local_variables_initializer(), tf.global_variables_initializer()]\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "\n",
    "    sess.run(init_vars)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "\n",
    "    for epoch in range(FLAGS.epochs):\n",
    "        sess.run(iterator.initializer)\n",
    "        print('Actual epoch: {}'.format(epoch))\n",
    "\n",
    "        flag = True  # Show only first batch of epoch\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                sess.run(optimizer)\n",
    "                if flag:\n",
    "                    # Get input and recover output images comparison\n",
    "                    summ, target, output_ = sess.run([merged_summary_op, input_batch, output])\n",
    "                    f, axarr = plt.subplots(FLAGS.test_image_number, 2)\n",
    "\n",
    "                    for j in range(FLAGS.test_image_number):\n",
    "                        for pos, im in enumerate([target, output_]):\n",
    "                            axarr[j, pos].imshow(im[j].reshape((28, 28)), cmap='gray')\n",
    "                            axarr[j, pos].axis('off')\n",
    "\n",
    "                    plt.savefig(os.path.join(results_folder, 'Train/Epoch_{}').format(epoch))\n",
    "                    plt.close(f)\n",
    "                    flag = False\n",
    "                    writer.add_summary(summ, epoch)\n",
    "\n",
    "                    # Create artificial image from unit norm sample\n",
    "                    artificial_image = sess.run(output, feed_dict={z: np.random.normal(0, 1, (1, FLAGS.latent_dim))})\n",
    "                    plt.figure()\n",
    "                    with sns.axes_style(\"white\"):\n",
    "                        plt.imshow(artificial_image[0].reshape((28, 28)), cmap='gray')\n",
    "                    plt.savefig(os.path.join(results_folder, 'Test/{}'.format(epoch)))\n",
    "                    plt.close()\n",
    "\n",
    "                    # Create plot of latent space (only if latent dimensions are 2)\n",
    "                    if FLAGS.latent_dim == 2 and FLAGS.plot_latent:\n",
    "                        coords = sess.run(z, feed_dict={input_batch: test_images[..., np.newaxis]/255.})\n",
    "                        colormap = ListedColormap(sns.color_palette(sns.hls_palette(10, l=.45 , s=.8)).as_hex())\n",
    "                        plt.scatter(coords[:, 0], coords[:, 1], c=test_labels, cmap=colormap)\n",
    "\n",
    "                        cbar = plt.colorbar()\n",
    "\n",
    "                        # plt.axis('off')\n",
    "                        plt.title('Latent space')\n",
    "                        plt.savefig(os.path.join(results_folder, 'Test/Latent_{}'.format(epoch)))\n",
    "                        plt.close()\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "\n",
    "        # Create mesh grid of values\n",
    "        values = np.arange(-3, 4, .5)\n",
    "        xx, yy = np.meshgrid(values, values)\n",
    "        input_holder = np.zeros((1, 2))\n",
    "        # Matrix that will contain the grid of images\n",
    "        container = np.zeros((28 * len(values), 28 * len(values)))\n",
    "\n",
    "        for row in range(xx.shape[0]):\n",
    "            for col in range(xx.shape[1]):\n",
    "                input_holder[0, :] = [xx[row, col], yy[row, col]]\n",
    "                artificial_image = sess.run(output, feed_dict={z: input_holder})\n",
    "                container[row * 28: (row + 1) * 28, col * 28: (col + 1) * 28] = np.squeeze(artificial_image)\n",
    "\n",
    "        plt.imshow(container, cmap='gray')\n",
    "        plt.savefig(os.path.join(results_folder, 'Test/Space_{}'.format(epoch)))\n",
    "        plt.close(  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "cvae.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu] *",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
